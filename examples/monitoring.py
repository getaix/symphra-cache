"""
ç›‘æ§ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ CacheMonitor å’Œå„ç§ç›‘æ§å¯¼å‡ºå™¨æ¥ç›‘æ§ç¼“å­˜æ€§èƒ½ã€‚
"""

import asyncio
import time

from symphra_cache import CacheManager, MemoryBackend
from symphra_cache.monitoring import CacheMonitor, PrometheusExporter, StatsDExporter


def simulate_cache_operations(cache: CacheManager, operations: int = 100) -> None:
    """æ¨¡æ‹Ÿç¼“å­˜æ“ä½œä»¥ç”Ÿæˆç›‘æ§æ•°æ®"""
    print(f"  æ­£åœ¨æ¨¡æ‹Ÿ {operations} æ¬¡ç¼“å­˜æ“ä½œ...")

    # æ¨¡æ‹Ÿæ··åˆçš„è¯»å†™æ“ä½œ
    for i in range(operations):
        key = f"test:key:{i % 10}"  # é‡å¤ä½¿ç”¨10ä¸ªé”®ä»¥äº§ç”Ÿå‘½ä¸­

        if i % 3 == 0:
            # 30% çš„å†™æ“ä½œ
            cache.set(key, f"value_{i}", ttl=3600)
        else:
            # 70% çš„è¯»æ“ä½œ
            cache.get(key)

        # æ¯10æ¬¡æ“ä½œä¼‘æ¯ä¸€ä¸‹
        if i % 10 == 0:
            time.sleep(0.001)  # 1ms ä¼‘æ¯


async def demonstrate_basic_monitoring():
    """æ¼”ç¤ºåŸºç¡€ç›‘æ§åŠŸèƒ½"""
    print("=== åŸºç¡€ç›‘æ§ç¤ºä¾‹ ===\n")

    cache = CacheManager(backend=MemoryBackend())
    monitor = CacheMonitor(cache)

    # æ¨¡æ‹Ÿä¸€äº›ç¼“å­˜æ“ä½œ
    simulate_cache_operations(cache, 50)

    # æ”¶é›†æŒ‡æ ‡
    print("1. æ”¶é›†ç¼“å­˜æŒ‡æ ‡...")
    metrics = await monitor.collect_metrics()

    # æ˜¾ç¤ºæŒ‡æ ‡
    print("2. ç¼“å­˜æŒ‡æ ‡:")
    metrics_dict = metrics.to_dict()
    for key, value in metrics_dict.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.4f}")
        else:
            print(f"  {key}: {value}")

    # æ˜¾ç¤ºå¥åº·çŠ¶æ€
    print("\n3. å¥åº·çŠ¶æ€:")
    health = monitor.get_health_status()
    for key, value in health.items():
        print(f"  {key}: {value}")


async def demonstrate_prometheus_export():
    """æ¼”ç¤º Prometheus æŒ‡æ ‡å¯¼å‡º"""
    print("\n=== Prometheus å¯¼å‡ºç¤ºä¾‹ ===\n")

    cache = CacheManager(backend=MemoryBackend())
    monitor = CacheMonitor(cache)
    exporter = PrometheusExporter(
        monitor,
        namespace="myapp",
        subsystem="cache",
        labels={"instance": "test-instance", "environment": "development"},
    )

    # æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ
    simulate_cache_operations(cache, 100)

    # ç”Ÿæˆ Prometheus æ ¼å¼æŒ‡æ ‡
    print("1. ç”Ÿæˆ Prometheus æ ¼å¼æŒ‡æ ‡...")
    metrics_text = exporter.generate_metrics()

    print("2. Prometheus æŒ‡æ ‡è¾“å‡º:")
    print("-" * 50)
    print(metrics_text)
    print("-" * 50)

    # æ¼”ç¤º Pushgateway é›†æˆ
    print("\n3. Pushgateway é›†æˆæ¼”ç¤º:")
    try:
        # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯æ¼”ç¤ºå®¢æˆ·ç«¯åˆ›å»ºï¼Œä¸å®é™…è¿æ¥
        pushgateway_client = exporter.create_pushgateway_client(
            gateway_url="http://localhost:9091",
            job_name="cache_monitoring",
            instance="test-instance",
        )
        print(f"  Pushgateway URL: {pushgateway_client.get_push_url()}")
        print("  Pushgateway å®¢æˆ·ç«¯å·²åˆ›å»ºï¼ˆéœ€è¦å®é™…çš„ Pushgateway æœåŠ¡å™¨ï¼‰")
    except Exception as e:
        print(f"  Pushgateway é›†æˆå¤±è´¥: {e}")


async def demonstrate_statsd_export():
    """æ¼”ç¤º StatsD æŒ‡æ ‡å¯¼å‡º"""
    print("\n=== StatsD å¯¼å‡ºç¤ºä¾‹ ===\n")

    cache = CacheManager(backend=MemoryBackend())
    monitor = CacheMonitor(cache)

    # åˆ›å»º StatsD å¯¼å‡ºå™¨ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å¼ï¼Œä¸å®é™…å‘é€ï¼‰
    exporter = StatsDExporter(
        monitor, host="localhost", port=8125, prefix="myapp.cache", sample_rate=1.0, protocol="udp"
    )

    # æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ
    simulate_cache_operations(cache, 50)

    # ç”Ÿæˆ StatsD æ ¼å¼æŒ‡æ ‡
    print("1. ç”Ÿæˆ StatsD æ ¼å¼æŒ‡æ ‡...")
    statsd_metrics = exporter.generate_all_metrics()

    print("2. StatsD æŒ‡æ ‡è¾“å‡º:")
    for metric in statsd_metrics:
        print(f"  {metric}")

    # æ¼”ç¤ºè¿æ¥çŠ¶æ€
    print("\n3. è¿æ¥çŠ¶æ€:")
    status = exporter.get_connection_status()
    for key, value in status.items():
        print(f"  {key}: {value}")

    # æ¼”ç¤ºè‡ªå®šä¹‰æŒ‡æ ‡
    print("\n4. æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡:")
    exporter.add_custom_metric("custom_metric", 42.5, "g")
    exporter.add_custom_metric("operation_count", 100, "c")

    custom_metrics = exporter.generate_all_metrics()
    print("  åŒ…å«è‡ªå®šä¹‰æŒ‡æ ‡çš„è¾“å‡º:")
    for metric in custom_metrics:
        if "custom" in metric:
            print(f"  {metric}")


async def demonstrate_real_time_monitoring():
    """æ¼”ç¤ºå®æ—¶ç›‘æ§"""
    print("\n=== å®æ—¶ç›‘æ§ç¤ºä¾‹ ===\n")

    cache = CacheManager(backend=MemoryBackend())
    monitor = CacheMonitor(cache)

    print("1. å¼€å§‹å®æ—¶ç›‘æ§ï¼ˆ5ç§’ï¼‰...")
    print("  æ¯ç§’æ˜¾ç¤ºä¸€æ¬¡æŒ‡æ ‡å¿«ç…§")
    print("-" * 60)

    for i in range(5):
        # æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
        simulate_cache_operations(cache, 20)

        # æ”¶é›†å¹¶æ˜¾ç¤ºæŒ‡æ ‡
        metrics = await monitor.collect_metrics()
        metrics_dict = metrics.to_dict()

        timestamp = time.strftime("%H:%M:%S")
        print(f"\n  [{timestamp}] ç¬¬ {i + 1} æ¬¡é‡‡æ ·:")
        print(f"    æ“ä½œæ€»æ•°: {metrics_dict.get('total_operations', 0)}")
        print(f"    å‘½ä¸­ç‡: {metrics_dict.get('hit_rate', 0):.4f}")
        print(f"    ç¼“å­˜å¤§å°: {metrics_dict.get('cache_size', 0)}")
        print(f"    GET å¹³å‡å»¶è¿Ÿ: {metrics_dict.get('get_latency', {}).get('avg', 0):.3f}ms")
        print(f"    SET å¹³å‡å»¶è¿Ÿ: {metrics_dict.get('set_latency', {}).get('avg', 0):.3f}ms")

        # ç­‰å¾…1ç§’
        await asyncio.sleep(1)

    print("-" * 60)
    print("2. å®æ—¶ç›‘æ§å®Œæˆ")


async def demonstrate_metric_types():
    """æ¼”ç¤ºä¸åŒç±»å‹çš„ç›‘æ§æŒ‡æ ‡"""
    print("\n=== æŒ‡æ ‡ç±»å‹ç¤ºä¾‹ ===\n")

    cache = CacheManager(backend=MemoryBackend())
    monitor = CacheMonitor(cache)

    # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ“ä½œ
    print("1. æ¨¡æ‹Ÿå„ç§ç¼“å­˜æ“ä½œ...")

    # å¤§é‡è¯»æ“ä½œ
    for i in range(50):
        cache.get(f"read:key:{i % 5}")

    # ä¸€äº›å†™æ“ä½œ
    for i in range(20):
        cache.set(f"write:key:{i}", f"value_{i}", ttl=3600)

    # ä¸€äº›åˆ é™¤æ“ä½œ
    for i in range(10):
        cache.delete(f"delete:key:{i}")

    # æ”¶é›†è¯¦ç»†æŒ‡æ ‡
    print("\n2. è¯¦ç»†æŒ‡æ ‡åˆ†æ:")
    metrics = monitor.metrics

    print(f"  GET æ“ä½œ: {metrics.get_count}")
    print(f"  SET æ“ä½œ: {metrics.set_count}")
    print(f"  DELETE æ“ä½œ: {metrics.delete_count}")
    print(f"  å‘½ä¸­æ¬¡æ•°: {metrics.hit_count}")
    print(f"  æœªå‘½ä¸­æ¬¡æ•°: {metrics.miss_count}")
    print(f"  å‘½ä¸­ç‡: {metrics.get_hit_rate():.4f}")

    # å»¶è¿Ÿç»Ÿè®¡
    print("\n3. å»¶è¿Ÿç»Ÿè®¡:")
    get_latency = metrics.get_latency_stats("get")
    set_latency = metrics.get_latency_stats("set")

    print(
        f"  GET å»¶è¿Ÿ - æœ€å°: {get_latency['min'] or 0:.3f}ms, æœ€å¤§: {get_latency['max'] or 0:.3f}ms, å¹³å‡: {get_latency['avg']:.3f}ms"
    )
    print(
        f"  SET å»¶è¿Ÿ - æœ€å°: {set_latency['min'] or 0:.3f}ms, æœ€å¤§: {set_latency['max'] or 0:.3f}ms, å¹³å‡: {set_latency['avg']:.3f}ms"
    )


async def demonstrate_monitoring_lifecycle():
    """æ¼”ç¤ºç›‘æ§å™¨çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    print("\n=== ç›‘æ§ç”Ÿå‘½å‘¨æœŸç¤ºä¾‹ ===\n")

    cache = CacheManager(backend=MemoryBackend())
    monitor = CacheMonitor(cache)

    print("1. åˆå§‹çŠ¶æ€:")
    print(f"  ç›‘æ§å¯ç”¨: {monitor.is_enabled()}")

    # å¯ç”¨ç›‘æ§
    monitor.enable()
    print("\n2. å¯ç”¨ç›‘æ§å:")
    print(f"  ç›‘æ§å¯ç”¨: {monitor.is_enabled()}")

    # æ‰§è¡Œä¸€äº›æ“ä½œ
    simulate_cache_operations(cache, 30)

    # æ”¶é›†æŒ‡æ ‡
    metrics1 = await monitor.collect_metrics()
    print(f"  æ“ä½œå‰æŒ‡æ ‡ - æ€»æ“ä½œæ•°: {metrics1.get_total_operations()}")

    # é‡ç½®æŒ‡æ ‡
    monitor.reset_metrics()
    print("\n3. é‡ç½®æŒ‡æ ‡å:")

    # å†æ‰§è¡Œä¸€äº›æ“ä½œ
    simulate_cache_operations(cache, 20)

    metrics2 = await monitor.collect_metrics()
    print(f"  æ“ä½œåæŒ‡æ ‡ - æ€»æ“ä½œæ•°: {metrics2.get_total_operations()}")

    # ç¦ç”¨ç›‘æ§
    monitor.disable()
    print("\n4. ç¦ç”¨ç›‘æ§å:")
    print(f"  ç›‘æ§å¯ç”¨: {monitor.is_enabled()}")

    # æ‰§è¡Œæ“ä½œä½†ä¸æ”¶é›†æŒ‡æ ‡
    simulate_cache_operations(cache, 10)

    metrics3 = await monitor.collect_metrics()
    print(f"  ç¦ç”¨åæŒ‡æ ‡ - æ€»æ“ä½œæ•°: {metrics3.get_total_operations()}")


async def demonstrate_exporter_configuration():
    """æ¼”ç¤ºå¯¼å‡ºå™¨é…ç½®é€‰é¡¹"""
    print("\n=== å¯¼å‡ºå™¨é…ç½®ç¤ºä¾‹ ===\n")

    cache = CacheManager(backend=MemoryBackend())
    monitor = CacheMonitor(cache)

    # Prometheus å¯¼å‡ºå™¨é…ç½®
    print("1. Prometheus å¯¼å‡ºå™¨é…ç½®:")
    prom_exporter = PrometheusExporter(
        monitor,
        namespace="production",
        subsystem="cache",
        labels={"service": "user-service", "version": "1.0.0"},
    )

    print(f"  å‘½åç©ºé—´: {prom_exporter.namespace}")
    print(f"  å­ç³»ç»Ÿ: {prom_exporter.subsystem}")
    print(f"  æ ‡ç­¾: {prom_exporter.labels}")

    # æ·»åŠ åŠ¨æ€æ ‡ç­¾
    prom_exporter.update_labels({"region": "us-west-1", "zone": "a"})
    print(f"  æ›´æ–°åæ ‡ç­¾: {prom_exporter.labels}")

    # StatsD å¯¼å‡ºå™¨é…ç½®
    print("\n2. StatsD å¯¼å‡ºå™¨é…ç½®:")
    statsd_exporter = StatsDExporter(
        monitor,
        host="statsd.example.com",
        port=8125,
        prefix="production.user_service.cache",
        sample_rate=0.8,  # 80% é‡‡æ ·
        protocol="tcp",
        batch_size=20,
    )

    print(f"  ä¸»æœº: {statsd_exporter.host}")
    print(f"  ç«¯å£: {statsd_exporter.port}")
    print(f"  å‰ç¼€: {statsd_exporter.prefix}")
    print(f"  é‡‡æ ·ç‡: {statsd_exporter.sample_rate}")
    print(f"  åè®®: {statsd_exporter.protocol}")
    print(f"  æ‰¹é‡å¤§å°: {statsd_exporter.batch_size}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š Symphra Cache ç›‘æ§ç¤ºä¾‹\n")

    # æ¼”ç¤ºå„ç§ç›‘æ§åŠŸèƒ½
    await demonstrate_basic_monitoring()
    await demonstrate_prometheus_export()
    await demonstrate_statsd_export()
    await demonstrate_real_time_monitoring()
    await demonstrate_metric_types()
    await demonstrate_monitoring_lifecycle()
    await demonstrate_exporter_configuration()

    print("\nâœ… æ‰€æœ‰ç›‘æ§ç¤ºä¾‹å®Œæˆï¼")
    print("\nç›‘æ§åŠŸèƒ½ç‰¹ç‚¹:")
    print("  â€¢ æä¾›å…¨é¢çš„ç¼“å­˜æ€§èƒ½æŒ‡æ ‡")
    print("  â€¢ æ”¯æŒ Prometheus å’Œ StatsD å¯¼å‡º")
    print("  â€¢ å®æ—¶ç›‘æ§å’Œå†å²æ•°æ®åˆ†æ")
    print("  â€¢ çµæ´»çš„é…ç½®å’Œæ ‡ç­¾æ”¯æŒ")
    print("  â€¢ å®Œæ•´çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†")
    print("  â€¢ æ”¯æŒè‡ªå®šä¹‰æŒ‡æ ‡æ‰©å±•")


if __name__ == "__main__":
    asyncio.run(main())
